{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc=SparkContext()\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-74-1.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb64c34d550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_in_a_partition(idx, iterator):\n",
    "  count = 0\n",
    "  for _ in iterator:\n",
    "    count += 1\n",
    "  return idx, count\n",
    "\n",
    "def keeper_func(x,int_words):\n",
    "    out = []\n",
    "    if len(x) != 2:\n",
    "        out = []\n",
    "    else:\n",
    "        sep = x[1].split('\\t')\n",
    "        if len(sep) != 5:\n",
    "            out = []\n",
    "        else:\n",
    "            try:\n",
    "                word = sep[0].lower()\n",
    "                if word in int_words:\n",
    "                    out.append(word)\n",
    "                    for item in sep[1:]:\n",
    "                        out.append(item)\n",
    "            except:\n",
    "                pass\n",
    "    final_out=[]\n",
    "    if len(out) == 5:\n",
    "        final_out = out\n",
    "    return tuple(final_out) # VERY IMPORTANT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import csv\n",
    "\n",
    "# Without these keys you cannot access s3.\n",
    "# Run this from command line, which means before entering the pyspark shell\n",
    "\n",
    "#export AWS_ACCESS_KEY_ID=<ACCESS_KEY_ID>\n",
    "#export AWS_SECRET_ACCESS_KEY=<SECRET_ACCESS_KEY>\n",
    "\n",
    "# Load Data from us-east-1 region\n",
    "# It is recommended to build your cluster in this region.\n",
    "# I generated a 1 Master, 5 Slaves m4.xlarge instances.\n",
    "# Once the cluster is set up.\n",
    "# The entire processing of the data should not take more than 20 minutes.\n",
    "\n",
    "rdd2 = sc.sequenceFile(\"s3://datasets.elasticmapreduce/ngrams/books/20090715/eng-us-all/2gram/data\",\n",
    "\"org.apache.hadoop.io.Text\",\n",
    "\"org.apache.hadoop.io.LongWritable\", minSplits=1000)\n",
    "\n",
    "\"\"\" To test the code with a samll dataset.\n",
    "# Read the Sample File from local\n",
    "with open('Sample_big.csv', 'rb') as csvfile:\n",
    "    sample_data = []\n",
    "    data = csv.reader(csvfile,delimiter='\\t')\n",
    "    for row in data:\n",
    "        sample_data.append(row)\n",
    "# Pre-process data\n",
    "rdd2 = sc.parallelize(sample_data,100)\n",
    "data_per_part = rdd2.mapPartitionsWithIndex(count_in_a_partition).collect()\n",
    "\"\"\"\n",
    "\n",
    "# Interesting words\n",
    "int_words = ['good night', 'good morning']\n",
    "#Keep only data from your int_words\n",
    "rdd3 = rdd2.map(lambda x: keeper_func(x,int_words))\n",
    "rdd4  = rdd3.filter(lambda x: x)\n",
    "# Now the data should be managable and we can cache it\n",
    "rdd4.cache()\n",
    "# Super important, transforms tuples into key pairs.\n",
    "rdd5 = rdd4.map(lambda x : (x[0], x[1:]))\n",
    "# Group Everything By Key\n",
    "total_data = rdd5.groupByKey().map(lambda x : (x[0], list(x[1]))).collect()\n",
    "\n",
    "# Save data to File\n",
    "myfile = open('output_28_01_2018.csv','w')\n",
    "with myfile:\n",
    "    writer = csv.writer(myfile)\n",
    "    writer.writerows(total_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import collections\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Load File \"\"\"\n",
    "\n",
    "with open('output_28_01_2018.csv', \"rt\") as csvfile:\n",
    "    total_data = []\n",
    "    data = csv.reader(csvfile)\n",
    "    for row in data:\n",
    "        total_data.append(row)\n",
    "\n",
    "\"\"\" Plot Data \"\"\"\n",
    "\n",
    "def reorder_plot(data,color,plt):\n",
    "    dc = dict()\n",
    "    #plt.figsize(200,200)\n",
    "    # Get Data Together\n",
    "    for item in data:\n",
    "        if item[0] not in dc.keys():\n",
    "            dc[item[0]] = (int(item[1]),int(item[2]))\n",
    "        else:\n",
    "            dc[item[0]] = (dc[item[0]][0]+int(item[1]),dc[item[0]][1]+int(item[2]))\n",
    "    od_dc = collections.OrderedDict(sorted(dc.items()))\n",
    "    # Re-order to plot\n",
    "    year = np.empty([len(od_dc), 1])\n",
    "    occu_ratio = np.empty([len(od_dc), 1])\n",
    "    for i,key in enumerate(od_dc.keys()):\n",
    "        year[i,0] = int(key)\n",
    "        occu_ratio[i,0] = float(od_dc[key][0])/float(od_dc[key][1])\n",
    "    plt.plot(year,occu_ratio,color)\n",
    "    return plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "color = ['-or','-ob','-og','-ok','-oy']\n",
    "names = []\n",
    "c = 0\n",
    "\n",
    "\n",
    "for i,item in enumerate(total_data):\n",
    "    data = []\n",
    "    if item[0] in ['peace', 'war']:\n",
    "        names.append(item[0])\n",
    "        a = item[1].split('), (')\n",
    "        for algo in a:\n",
    "            for elemento in string.punctuation:\n",
    "                algo = algo.replace(elemento,\" \")\n",
    "            values = algo.split()\n",
    "            values = values[0:]\n",
    "            data.append(values)\n",
    "        plt = reorder_plot(data,color[c],plt)\n",
    "        c+=1\n",
    "\n",
    " \n",
    "\n",
    "ax = plt.subplot(111)\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# Only show ticks on the left and bottom spines\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Occurence Ratio')\n",
    "plt.legend(names,shadow=True)\n",
    "plt.ylim(ymin=.5,ymax=3)\n",
    "plt.xlim(xmin=1800,xmax=2018)\n",
    "plt.tick_params(top='off', right='off')      \n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('a.pdf',dpi=40)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
